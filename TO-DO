# Baseline GTA-clean+MS+VGG
10/05
(HP) 1. Multi-feature agnostic
  - 回歸ＤＳＮ設計，確定做在output space或feature space哪個performance比較好。
(HP) 2. When do we start using s2t translated labels ?
  - 理論上一開始的s2t quality比較低或比較模糊，可能導致產生的圖片與source labels不相符，測試在後面一點開始transfer是否能增進performance與穩定度。
(WC) 3. Disable s2t translated label (i.e., only keep DSN architectures and comapred to Dennis')
  - Ablatino study. 如果這個設定會比enable差表示translated label有用，除此之外如果該performance比Dennis好，我們同時可以證明ＤＳＮ架構有好處。
(WC) 4. Add a regularization to minimize the l1 norm of F_s and F_s2t
  - translated labels某種程度而言也是在要求轉換過後的圖應與source經過shared encoder後的output應一致。該實驗探討直接在feature space上做是否有更多好處。
(HP) 5. Check if private encoders work
  - one of our main contribution is the DSN architecture, so it's important to check if our private encoder works as a part of DSN.
(WC) 6. Modify the decoder archicture into "Y" shape
  - improve the s2t image quality, because we think s2t is sharper than target image
(HP) 7. Dennis code run on GTA_Clean

10/12
(WC) 8. Pretrain private encoder and decoder -> freeze shared encoder layer3, layer4
  - We think the different initial method for the model will cause imbanlance problem and avoid private encoder working. 
(HP) 9. Add style transfer skill "Adain" on the image translation loss. Low level feature of VGG, and match channel wise mean
  - Walon suggest this idea make sense for style transfer
(HP) 10. Which layer of feature is better to be the input of the private encoder ? layer0, layer1
  - make sure which layer is better for disentanglement
(HP) 11. latent reconstruction
  - Walon think it will be benefitial for disentanglement


10/15
Three possible ways
  - Verify segmentation does not contain texture information in deeper levels
  - Keep DSN! Tuning todo_9 to disentangle texture and structure successfully and achieve similar performance meanwhile
  - Pure augmentation
  
(WC) 12. Traing hyper-base without tranlsated labels
(WC) 13. Verify our assumption. Use only layer4 feats to reconstrcut original input images.
  - Fixed Dennis's segmentation model weights to do so
  - With only one decoder and no other inputs.
(HP) 14. Tuning todo_9
  a. Training todo_9 without adversarial loss
    - check if it can generate better image quality and keep the structure at the same time
  b. Adjusting weights of mean matching [1/8, 1/16, 1/32, 0 ,0]
    - just adjust
  c. Training todo_9 with variance matching only
    - just train
  d. Training todo_9 with variance and mean matching
    - just train la !
  e. Training todo_9 without translated labels (lower priority)
    - todo_9 is not stable yet. It's meaningless to do this.
(WC) 15. Using the same encoder for both s2t and t2s images
  - Ideally, source dataset contains variety of styles which helps the encoder to learn different styles.
  In this experiement, we hope that by using the same encoder, target images can benefit from various source styles and generate more styles.
  - Remove the domain codes
  
10/19
  Experiments may contain:
    - GTA5 -> CityScapes segmentation performance
    - SYNTHIA -> CityScapes segmentation performance
    - Ablation study for loss choice
    - Ablation study for differnet layer choice
    - Visualization of prediction segmentation map
    - Visualization of disentangle ability
    
  16. Full-image hyper base
  17. Hyper base with reconstruction weight self-mean, self-var merge
  18. SYNTHIA loader
  
  ultimate-base crop
  (WC) 19. ultimate-base, private encoder input = layer3
  (WC) 20. source only
  (WC) 21. DSN w/o adversarial loss
  (WC) 22. Dennis model
  (WC) 23. True DeepLab2 shared-encoder
  (WC) 24. PSP shared-encoder 
  (HP) 25. DSN w/ 2x segmentation loss
  
# CVPR template 
(HP) do it 
